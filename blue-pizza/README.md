# Data Beans - From Beans to Screams

### Summary
When you are a Data Engineer, Analyst or Scientist the first step to work with the data is to understand the data:
- What they represent in the context of a process or a situation
- Their structure and content.
- When it has been generated,  frequency at which it is sent or time lag before it is available.
- How the different datasets relate with each other and how they help you paint a situation.
Today, we will use the context of a coffee shop example as our setup and demonstrate how we can perform a root cause analysis over multiple data structures and types to  get the details of why suddenly our coffee shop sees a surge in bad reviews.

### What you'll learn
Using BigQuery and Canvas we will:
- Get insight fast leveraging BiQuery as a single pane of glass for all data: Structured, semi-structured and unstructured ones
- Leverage Gemini to understand your data
- Perform data discovery and exploration using natural language
- Generate complex SQL statements from natural language prompts
- Use the contextual assistant to get explanations
- Generate appealing visualization to understand your data
- Leverage an LLM model to perform visual inspection 

### Lab can be deployed in 2 ways:

| Type | Description | Instruction  |
|-------------|-------------------------------------------------------------------------------------------------------|-------------|
| Standalone | Use the terraform script to deploy in your own environment and follow the instruction | [link](https://github.com/c-damien/gcp-public-demos/tree/main/data-beans/terraform-script/standalone) |
| Qwiklab | Use the selfpaced platform to go through the lab (you will need an account) | [link](https://explore.qwiklabs.com/labs/14798) |
